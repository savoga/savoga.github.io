I"y	<p><strong>Logistic regression</strong></p>

<p>Logistic regression is used for binary classification.</p>

<p>It is quite similar to a simple linear regression in the sense that the objective is to find optimal weights $\omega$ to predict a variable. However, in the logistic regression we use a sigmoïd function.</p>

<p>Rem: “logistic” because the logistic law has a sigmoïd function as a repartition function.</p>

<p><ins>Rationale behind the use of the sigmoïd function</ins>:</p>

<p>We look for the <em>à posteriori</em> probability $\mathbb{P}(x | y=1) = \pi (x) = \hat{y}$.</p>

<p>The predicted variable $\hat{y}$ is thus a probability.</p>

<p>The sigmoïd function: $\sigma: z \to \frac{1}{1+e^{-z}}$ is well adapted because we want an output that is included in $[0,1]$.</p>

<p><img src="/assets/img/sigmoid.png" alt="image" height="30%" width="30%" /></p>

<p>Classification function: $\widehat{f}_{\omega}(x) = \sigma(\omega x)$ with a threshold</p>

<p><ins>Loss function</ins></p>

<p>If $y = 1$, we want $\sigma(\omega x)$ to be high =&gt; $1 - \sigma(\omega x)$ should be low. The loss function should be increasing with $1 - \sigma(\omega x) = 1 - \frac{1}{1+e^{-\omega x}} = \frac{1}{1+e^{\omega x}}$. Equivalently, it should be increasing with $1 + e^{-\omega x}$</p>

<p>More generally, the loss function is defined as such: $\ell(f_{\omega}, (x,y)) = log(1 + e^{-y \omega x})$ (adding $y$ in the expression allows to take into account cases when $y = 1$ and $y = -1$).</p>

<p>Recall that the log is a monotonic function.</p>

<p><ins>Estimation</ins></p>

<p>The advantage of the logistic loss function is that it is a convex function. Hence the ERM problem can be solved efficiently using santard methods.</p>

<p>Estimation is done using maximum likelihood. Maximum likelihood is finding the parameter that maximizes the probability to have a specific event $(x_i, y_i)$. We want to maximize the \textit{à posteriori} probability that depends on $x$:</p>

<p>$L(\omega, b) = \prod_{i=1}^n \pi(x_i)^{y_i}(1-\pi(x_i))^{1-y_i}$</p>

<p>This equation has no analytic solution. We use a numeric method to find the optimal parameters (see optimizaton algorithms).</p>

<p>See <em>Neural Network</em> section for more details on optimization.</p>

<p>Note: logistic regression is really a linear model since the objective is to find $\omega$ that is the slope of the line $\omega ^Tx + b$.</p>
:ET