<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Roc</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
  </head>
  <body>
    <nav>
    
    <a href=/ >
        Home
    </a>
    
    <a href=/about.html >
        About
    </a>
    
    <a href=/machinelearning.html >
        ML
    </a>
    
    <a href=/stats.html >
        Stats
    </a>
    
    <a href=/projects.html >
        Projects
    </a>
    
    <a href=/extra.html >
        Extra
    </a>
    
</nav>
    <script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
inlineMath: [['$','$'], ['\\(','\\)']],
processEscapes: true},
jax: ["input/TeX","input/MathML","input/AsciiMath","output/CommonHTML"],
extensions: ["tex2jax.js","mml2jax.js","asciimath2jax.js","MathMenu.js","MathZoom.js","AssistiveMML.js", "[Contrib]/a11y/accessibility-menu.js"],
TeX: {
extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"],
equationNumbers: {
autoNumber: "AMS"
}
}
});
</script>

<p><strong>ROC curve</strong></p>

<p>ROC curve is used essentially for binary classification.</p>

<p>ROC = Receiver Operating Curve</p>

<p>[Use of the ROC curve]{.underline}</p>

<p>One model:</p>

<p>We use ROC curve to evaluate the performance of one classifying model
that we can obtain when varying a threshold.</p>

<p>Several models:</p>

<p>We use ROC curve to compare several classifying models in evaluating the
area under the curve (AUC) for a range of threshold.</p>

<p>[Intuition]{.underline}</p>

<p>After running the prediction of a specific model, we draw the confusion
matrix (actual vs predited) with a certain threshold.</p>

<p><img src="/assets/img/confusionmatrice.png" alt="image" height="20%" width="20%" /></p>

<p>We then modify the threshold and draw another confusion matrix.</p>

<p>The ROC graph summarizes all of the confusion matrices that each
threshold produced.</p>

<p><img src="/assets/img/overlap_roc.jpeg" alt="image" height="20%" width="20%" /></p>

<p>On the left picture we see the ability of a model to give a clear
distinction between the two classes. The curves are drawn from the
predictions and the actual results (<strong>how?</strong>)</p>

<p>[Implementation]{.underline}</p>

<p>1. Get probability predictions</p>

<p>2. Sort the probabilities (prediction)</p>

<p>3. Sort the validation (actual) according to previous sort</p>

<p>4. Loop on the sorted validation. At each iteration:</p>

<p>- increment TP or FP</p>

<p>- compute the TPR and FPR.</p>

<p>5. Plot (FPR, TPR)</p>

<p>See
<em>https://docs.eyesopen.com/toolkits/cookbook/python/plotting/roc.html</em>
for an implementation example, or data challenge Face_Recognition.</p>

  </body>
</html>