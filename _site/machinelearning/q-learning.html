<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Q Learning</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
  </head>
  <body>
    <nav>
    
    <a href=/ >
        Home
    </a>
    
    <a href=/about.html >
        About
    </a>
    
    <a href=/machinelearning.html >
        ML
    </a>
    
    <a href=/stats.html >
        Stats
    </a>
    
    <a href=/projects.html >
        Projects
    </a>
    
    <a href=/extra.html >
        Extra
    </a>
    
</nav>
    <script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
inlineMath: [['$','$'], ['\\(','\\)']],
processEscapes: true},
jax: ["input/TeX","input/MathML","input/AsciiMath","output/CommonHTML"],
extensions: ["tex2jax.js","mml2jax.js","asciimath2jax.js","MathMenu.js","MathZoom.js","AssistiveMML.js", "[Contrib]/a11y/accessibility-menu.js"],
TeX: {
extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"],
equationNumbers: {
autoNumber: "AMS"
}
}
});
</script>

<p><strong>Q-learning</strong></p>

<p>This algorithm is also based on $\epsilon$-greedy algorithm.</p>

\[\pi(s) \leftarrow
    \begin{cases}
     a^* \in argmax_a Q(s,a) &amp; \text{with probability}~1-\epsilon \\
    random &amp; \text{with probability}~\epsilon
    \end{cases}\]

<p>$\underline{Estimation}$: unlike SARSA, Q-learning aims at updating the estimator
using the best action at each iteration:</p>

<p>$\forall t, Q(s_t, a_t) \xleftarrow{\alpha} r_t + \gamma max_{a} Q(s_{t+1}, a)$</p>

<p>The only modification from SARSA is the following line:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Q[state_prev, action_prev] = (1 - alpha) *  Q[state_prev, action_prev] + alpha * (rewards[action_prev] + gamma * np.max(Q[state].data))
</code></pre></div></div>

  </body>
</html>