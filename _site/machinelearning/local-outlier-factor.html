<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Local Outlier Factor</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
  </head>
  <body>
    <nav>
    
    <a href=/ >
        Home
    </a>
    
    <a href=/about.html >
        About
    </a>
    
    <a href=/machinelearning.html >
        ML
    </a>
    
    <a href=/stats.html >
        Stats
    </a>
    
    <a href=/projects.html >
        Projects
    </a>
    
    <a href=/extra.html >
        Extra
    </a>
    
</nav>
    <script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
inlineMath: [['$','$'], ['\\(','\\)']],
processEscapes: true},
jax: ["input/TeX","input/MathML","input/AsciiMath","output/CommonHTML"],
extensions: ["tex2jax.js","mml2jax.js","asciimath2jax.js","MathMenu.js","MathZoom.js","AssistiveMML.js", "[Contrib]/a11y/accessibility-menu.js"],
TeX: {
extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"],
equationNumbers: {
autoNumber: "AMS"
}
}
});
</script>

<p><strong>Local Outlier Factor</strong></p>

<p>Local Outlier Factor is an unsupervised method used in anomaly
detection. It consists of comparing local density of train observations
VS local density of test observations.</p>

<p><ins>Reachability distance</ins></p>

<p>\(reachability \mbox{-} distance_k(A,B) = max \{ k \mbox{-} distance (B), d(A,B)\}\)
= reachability of A <em>from</em> B.<br />
$k \mbox{-} distance (B)$: distance from B to its kth nearest neighbor.</p>

<p>The reachability distance of A from B is <em>at least</em> the distance between
A and B or <em>at least</em> the distance of B’s neighbor.</p>

<p>When A is very far from B, it’s simply the distance between the two
points.</p>

<p>When A is very close to B, it’s the distance between B and its
neighbor.</p>

<p>The distance can be computed using different metrics: Euclidean
distance, Mahalanobis distance, etc.</p>

<p><ins>Local reachability density</ins></p>

<p>$lrd_k (A) = \frac{1}{\Sigma_{B \in N_k(A)} reachability \mbox{-} distance_k(A,B) / |N_k(A)|}$<br />
It’s the inverse of the average of reachability-distances of A from B.</p>

<p>When A is very far from its neighbors: sum of reachability distances is
high =&gt; local reachability density is small.</p>

<p><ins>Local Outlier Factor</ins></p>

<p>LOF computation consists of comparing the local densities of a point VS
its neighbors.<br />
$LOF_k(A) : =  \frac{\frac{\Sigma_{B \in N_k(A)}lrd_k(B)}{lrd_k(A)}}{|N_k(A)|}$<br />
$LOF_k(A) &gt; 1$: A is an outlier. Local reachability density of A is
small compared to its neighbors.</p>

<p>$LOF_k(A) &lt; 1$: A is an inlier.</p>

<p><img src="\assets\img\LOF.png" alt="image" height="15%" width="15%" /></p>

<p>On this figure, $k = 3$. We can see that the reachability distance of A
from its neighbors is high (red segments). The local reachability
density of A will thus be <strong>low</strong>.</p>

<p>On the contrary, the local reachability densities of its neighors is
<strong>high</strong> because each neighbor can be easily reached from their own
neighbors.</p>

<p>As a result, LOF would be high so A is an outlier.</p>

<p><ins>sklearn algorithm</ins></p>

<p>To score an observation, <em>fit</em> simply memorizes the train observations
(same as in knn).</p>

<p><em>score_samples</em> first finds the k-nearest neighbors from the train set
thanks to the given distance metric. It then computes the local outlier
factor for each test observation comparing the test observation local
density with its closest k-neighbors local densities in the train set.</p>

  </body>
</html>